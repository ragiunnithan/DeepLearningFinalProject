{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Classification of Acute Lymphocytic Leukemia (ALL) with Convolutional Neural Network\n\nImporting all the libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T17:07:27.681877Z","iopub.execute_input":"2021-11-26T17:07:27.682222Z","iopub.status.idle":"2021-11-26T17:07:27.704148Z","shell.execute_reply.started":"2021-11-26T17:07:27.682135Z","shell.execute_reply":"2021-11-26T17:07:27.702942Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport imageio\nimport numpy as np \nfrom timeit import default_timer as timer\nfrom tensorflow.keras.preprocessing import image \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.layers import BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.192864Z","iopub.execute_input":"2021-11-29T16:07:47.193889Z","iopub.status.idle":"2021-11-29T16:07:47.201009Z","shell.execute_reply.started":"2021-11-29T16:07:47.193851Z","shell.execute_reply":"2021-11-29T16:07:47.199730Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Getting the file paths for the data. The folder \"ALL\" has the data for Acute Lymphoblastic Leukemia (ALL) and the folder \"hem\" has data for the Normal. Currently we are loading only training and validation.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\nfold0_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0/all\"\nfold1_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1/all\"\nfold2_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2/all\"\n\n#hem is the normal one\nfold0_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0/hem\"\nfold1_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1/hem\"\nfold2_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2/hem\"\n\ntest_data = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data/\"\ntest_labels = pd.read_csv(\"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.211923Z","iopub.execute_input":"2021-11-29T16:07:47.212158Z","iopub.status.idle":"2021-11-29T16:07:47.237747Z","shell.execute_reply.started":"2021-11-29T16:07:47.212128Z","shell.execute_reply":"2021-11-29T16:07:47.236691Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"can_image_fnames = os.listdir(fold0_all)\n\n##Plotting a single image\ncancer_img = imageio.imread(os.path.join(fold0_all,\n                                         can_image_fnames[5]))\nplt.imshow(cancer_img)\nplt.title('Cancer - ALL Cell')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.240341Z","iopub.execute_input":"2021-11-29T16:07:47.241042Z","iopub.status.idle":"2021-11-29T16:07:47.516492Z","shell.execute_reply.started":"2021-11-29T16:07:47.240996Z","shell.execute_reply":"2021-11-29T16:07:47.515351Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"### Normal Cell","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.518237Z","iopub.execute_input":"2021-11-29T16:07:47.518674Z","iopub.status.idle":"2021-11-29T16:07:47.523994Z","shell.execute_reply.started":"2021-11-29T16:07:47.518620Z","shell.execute_reply":"2021-11-29T16:07:47.522627Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#blood cell without cancer - normal cells\nnrml_image_fnames = os.listdir(fold0_nrml)\nnrml_img = imageio.imread(os.path.join(fold0_nrml,\n                                         nrml_image_fnames[5]))\n\nplt.imshow(nrml_img)\nplt.title('Normal - Hem Cell')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.525852Z","iopub.execute_input":"2021-11-29T16:07:47.526761Z","iopub.status.idle":"2021-11-29T16:07:47.798656Z","shell.execute_reply.started":"2021-11-29T16:07:47.526714Z","shell.execute_reply":"2021-11-29T16:07:47.797647Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"The image is a 450 * 450 pixels with colors 'RGB'","metadata":{}},{"cell_type":"code","source":"nrml_img.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.802013Z","iopub.execute_input":"2021-11-29T16:07:47.802520Z","iopub.status.idle":"2021-11-29T16:07:47.809098Z","shell.execute_reply.started":"2021-11-29T16:07:47.802462Z","shell.execute_reply":"2021-11-29T16:07:47.807910Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"#### Read all the normal and cancer images as a list. Create a dataframe with file path as one column and the cancer type as another columns","metadata":{}},{"cell_type":"code","source":"def get_path_image(folder):\n    image_paths = []\n    image_fnames = os.listdir(folder) \n    for img_id in range(len(image_fnames)):\n        img = os.path.join(folder,image_fnames[img_id])\n        image_paths.append(img)\n    \n    return image_paths","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.810795Z","iopub.execute_input":"2021-11-29T16:07:47.811818Z","iopub.status.idle":"2021-11-29T16:07:47.821306Z","shell.execute_reply.started":"2021-11-29T16:07:47.811665Z","shell.execute_reply":"2021-11-29T16:07:47.820020Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"The number of cancer images in the train dataset is:","metadata":{}},{"cell_type":"code","source":"#image absolute paths for cancer cells and normal cells\ncancer_lst = []\n\nfor i in [fold0_all,fold1_all,fold2_all]:\n    paths = get_path_image(i)\n    cancer_lst.extend(paths)\n    \n    \nprint(len(cancer_lst))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.823011Z","iopub.execute_input":"2021-11-29T16:07:47.823657Z","iopub.status.idle":"2021-11-29T16:07:47.888656Z","shell.execute_reply.started":"2021-11-29T16:07:47.823611Z","shell.execute_reply":"2021-11-29T16:07:47.887378Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"The number of normal images in the train dataset.","metadata":{}},{"cell_type":"code","source":"normal_lst = []\nfor i in [fold0_nrml,fold1_nrml,fold2_nrml]:\n    paths = get_path_image(i)\n    normal_lst.extend(paths)\n   \n   \nprint(len(normal_lst))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.890765Z","iopub.execute_input":"2021-11-29T16:07:47.891370Z","iopub.status.idle":"2021-11-29T16:07:47.912517Z","shell.execute_reply.started":"2021-11-29T16:07:47.891322Z","shell.execute_reply":"2021-11-29T16:07:47.911446Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"cancer_dict = {\"x_col\":cancer_lst,\n          \"y_col\":[np.nan for x in range(len(cancer_lst))]}\n\n\ncancer_dict[\"y_col\"] = \"ALL\"\n\nnormal_dict = {\"x_col\":normal_lst,\n          \"y_col\":[np.nan for x in range(len(normal_lst))]}\n\n\nnormal_dict[\"y_col\"] = \"HEM\"\n\ncancer_df = pd.DataFrame(cancer_dict)\nnormal_df = pd.DataFrame(normal_dict)\n\ntrain_df = cancer_df.append(normal_df, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.914171Z","iopub.execute_input":"2021-11-29T16:07:47.914547Z","iopub.status.idle":"2021-11-29T16:07:47.930848Z","shell.execute_reply.started":"2021-11-29T16:07:47.914515Z","shell.execute_reply":"2021-11-29T16:07:47.929737Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"###  Bar chart for showing the number of images for each cell type.","metadata":{}},{"cell_type":"code","source":"\nplt.bar(['Normal', 'ALL'], [len(normal_lst), len(cancer_lst)])\nplt.title('Bar chart for showing the percentage of images in each cell type')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.933091Z","iopub.execute_input":"2021-11-29T16:07:47.933992Z","iopub.status.idle":"2021-11-29T16:07:48.136881Z","shell.execute_reply.started":"2021-11-29T16:07:47.933945Z","shell.execute_reply":"2021-11-29T16:07:48.136029Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### Pie chart showing the percentage of each cell type","metadata":{}},{"cell_type":"code","source":"plt.pie([len(train_df[train_df[\"y_col\"]==\"ALL\"]),len(train_df[train_df[\"y_col\"]==\"HEM\"])],\n        labels=[\"ALL\",\"Normal\"],autopct='%.f'\n       )\nplt.title('Pie Chart for percentage of each cell type')\nplt.gca()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:48.138609Z","iopub.execute_input":"2021-11-29T16:07:48.138979Z","iopub.status.idle":"2021-11-29T16:07:48.250635Z","shell.execute_reply.started":"2021-11-29T16:07:48.138922Z","shell.execute_reply":"2021-11-29T16:07:48.249627Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"select_normal = np.random.choice(normal_lst, 3, replace = False)\nselect_all = np.random.choice(cancer_lst, 3, replace = False)\n\n\nfig = plt.figure(figsize = (8,6))\n\nfor i in range(6):\n    if i < 3:\n        fp = select_normal[i]\n        label = 'Normal'\n    else:\n        fp = select_all[i-3]\n        label = 'ALL'\n    ax = fig.add_subplot(2, 3, i+1)\n    fn = image.load_img(fp, target_size = (100,100),\n                        color_mode='rgb')\n    plt.imshow(fn, cmap='Greys_r')\n    plt.title(label)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:48.252569Z","iopub.execute_input":"2021-11-29T16:07:48.253726Z","iopub.status.idle":"2021-11-29T16:07:48.672433Z","shell.execute_reply.started":"2021-11-29T16:07:48.253651Z","shell.execute_reply":"2021-11-29T16:07:48.671579Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Normal cells are mostly sperical and non-clefted cells with homogeneous chromatin and few vacuoles. ALL cells are irregularly shaped, clefted cells with hetrogeneous chromatin and multiple nucleoli and vacuoles.\n\n#### Average Images\nLet us average 50 cells of each sub class and see how much variation is there to identify meaningful differences.","metadata":{}},{"cell_type":"code","source":"#function for processing images to numpy array for creating mean\ndef img2np(fn_list, size = (32, 32)):\n   \n    i = 0\n    for fp in fn_list:\n        \n        current_image = image.load_img(fp, \n                                       target_size = size, \n                                       color_mode = 'grayscale')\n        \n        img_ts = image.img_to_array(current_image)\n        img_ts = [img_ts.ravel()]\n             \n        \n        \n        \n        if i == 0:\n            full_mat = img_ts\n            \n        else: \n            full_mat = np.concatenate((full_mat, img_ts))    \n        i = i + 1    \n    return full_mat\n\n\n\nnormal_npArray = img2np(normal_lst)\ncancer_npArray = img2np(cancer_lst)\n\n\n##Let us select 50 images to make the comparison clear\n\n\nnrml_images_sub = normal_npArray[:50]\ncnr_images_sub = cancer_npArray[:50]\n\n\ndef plt_mean(mat , title, size = (32, 32)):\n    \n    mean_img = np.mean(mat , axis = 0)\n    mean_img = mean_img.reshape(size)\n    plt.imshow(mean_img, vmin=0, vmax=255)\n    plt.title(f'Average {title}')\n    plt.axis('off')\n    plt.show()\n    return mean_img\n\nnrml_mean = plt_mean(nrml_images_sub , \"Normal\")\ncnr_mean = plt_mean(cnr_images_sub, \"Cancer - ALL\")","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:48.674573Z","iopub.execute_input":"2021-11-29T16:07:48.675580Z","iopub.status.idle":"2021-11-29T16:08:32.599771Z","shell.execute_reply.started":"2021-11-29T16:07:48.675538Z","shell.execute_reply":"2021-11-29T16:08:32.598702Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"The mean images can't detect much diferences between the classes. Though the ALL cells are bit larger than normal cell.","metadata":{}},{"cell_type":"markdown","source":"Reading the test and validation datset file locations and converting them to a dataframe","metadata":{}},{"cell_type":"code","source":"all_len = len(cancer_df)\nnorm_len = len(normal_df)\n\nnrm_size = int((norm_len/100) * 25)\nall_size = int((all_len/100) * 25)\nvalidation_df = pd.DataFrame()\nvalidation_df = validation_df.append(normal_df[0:nrm_size])\nvalidation_df = validation_df.append(cancer_df[0:all_size])    \n\ntrain_df = pd.DataFrame()\ntrain_df = train_df.append(normal_df[nrm_size : norm_len])\ntrain_df = train_df.append(cancer_df[all_size : all_len])   \n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:32.606434Z","iopub.execute_input":"2021-11-29T16:08:32.606952Z","iopub.status.idle":"2021-11-29T16:08:32.624538Z","shell.execute_reply.started":"2021-11-29T16:08:32.606909Z","shell.execute_reply":"2021-11-29T16:08:32.623089Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#Reading the validation data\ntest_list = get_path_image(test_data)\n\n\n##Convert the list to a dictionary. The labels are stored in the val_labels\n#3So we create a dictionary with x as the file name and y as the labels\n##The labels are having 0's and 1's.\n##0 means normal and 1 means cancer - ALL\n\ntest_dict = {\"x_col\":test_list,\n                   \"y_col\":test_labels[\"labels\"]}\n\ntest_df = pd.DataFrame(test_dict)\n\ntest_df[\"y_col\"].replace(to_replace = [1,0], value = [\"ALL\",\"HEM\"], inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:32.626648Z","iopub.execute_input":"2021-11-29T16:08:32.627475Z","iopub.status.idle":"2021-11-29T16:08:32.647764Z","shell.execute_reply.started":"2021-11-29T16:08:32.627429Z","shell.execute_reply":"2021-11-29T16:08:32.646669Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing\n\nWith keras, image preprocessing has become much easier. Instead of reading subfolders for all files, load pictures and converting it to numpy arrays\nKeras provides API calls. flow_from_dataframe allows us to input a pandas dataframe which contains the filenames, with or without extension, as one column and\nand a column which has the class names and directly read the images from the directory with their respective class names mapped.\n","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255 #pixel values are 255 maximum\n         )\n\n\ntest_datagen = ImageDataGenerator(\n        rescale=1./255 )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                  train_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),\n                 \n                  #batch_size = 32,\n                  color_mode = \"rgb\",\n                  shuffle = True,\n                  class_mode = \"binary\"\n                  )\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n                  validation_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),                  \n                  #batch_size = 32,\n                  color_mode = \"rgb\",\n                  shuffle = True,\n                  class_mode = \"binary\"\n                  )\n\n\ntest_generator = test_datagen.flow_from_dataframe(\n                  test_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),\n                  color_mode = \"rgb\",\n                  class_mode = \"binary\",\n                  shuffle = False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:32.649326Z","iopub.execute_input":"2021-11-29T16:08:32.649656Z","iopub.status.idle":"2021-11-29T16:08:33.617860Z","shell.execute_reply.started":"2021-11-29T16:08:32.649612Z","shell.execute_reply":"2021-11-29T16:08:33.616750Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"\n\n## A Model with one convolution and one dense layer\nConvolutional layer uses fewer parameters by forcing input values to share the parameters.\nDense layer uses a linear operation, meaning, every output is formed by the function based on every input.\nIn other words, every input is forced into the function, and then the \"Neural Network\" learns it's relation to the output. \nThere will be n*m connections, where n denotes the number of inputs and m denotes the number of outputs.\n\nThe output of the convolutional layer is formed by just a small size of inputs which depends on the filter's size and the weights are shared \nfor all pixels. The output is constructed by using the same co-efficient for all the pixels by using the neighbouring pixels as inputs.\n\n### Vanilla Model - 1C1D\n\n\n","metadata":{}},{"cell_type":"code","source":"# CNN layer\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (256, 256, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n##Dense layer\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:33.619537Z","iopub.execute_input":"2021-11-29T16:08:33.620340Z","iopub.status.idle":"2021-11-29T16:08:33.672600Z","shell.execute_reply.started":"2021-11-29T16:08:33.620292Z","shell.execute_reply":"2021-11-29T16:08:33.671565Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\n# compiling models\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy', 'Recall'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:33.674484Z","iopub.execute_input":"2021-11-29T16:08:33.674945Z","iopub.status.idle":"2021-11-29T16:08:33.688402Z","shell.execute_reply.started":"2021-11-29T16:08:33.674900Z","shell.execute_reply":"2021-11-29T16:08:33.686896Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"start = timer()\n\nhistory = model.fit(train_generator , \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:08:33.690130Z","iopub.execute_input":"2021-11-29T16:08:33.690613Z","iopub.status.idle":"2021-11-29T16:11:57.376341Z","shell.execute_reply.started":"2021-11-29T16:08:33.690566Z","shell.execute_reply":"2021-11-29T16:11:57.375079Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate the 1C1D model performance:","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:11:57.379042Z","iopub.execute_input":"2021-11-29T16:11:57.379613Z","iopub.status.idle":"2021-11-29T16:12:02.231873Z","shell.execute_reply.started":"2021-11-29T16:11:57.379572Z","shell.execute_reply":"2021-11-29T16:12:02.230673Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/paulgavrikov/visualkeras\nimport visualkeras\nvisualkeras.layered_view(model,legend=True,  to_file='1c1d.png')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:12:02.233515Z","iopub.execute_input":"2021-11-29T16:12:02.233936Z","iopub.status.idle":"2021-11-29T16:12:13.726674Z","shell.execute_reply.started":"2021-11-29T16:12:02.233902Z","shell.execute_reply":"2021-11-29T16:12:13.725635Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def myprint(s):\n    with open('modelsummary.txt','w+') as f:\n        print(s, file=f)\n\nmodel.summary(print_fn=myprint)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:12:13.728568Z","iopub.execute_input":"2021-11-29T16:12:13.728811Z","iopub.status.idle":"2021-11-29T16:12:13.742945Z","shell.execute_reply.started":"2021-11-29T16:12:13.728782Z","shell.execute_reply":"2021-11-29T16:12:13.742042Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"### 2C1D\nAdd another convolutional layer so as to create a model with 2 convolution and 1 Dense.\n\n","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:12:13.744889Z","iopub.execute_input":"2021-11-29T16:12:13.746025Z","iopub.status.idle":"2021-11-29T16:14:42.469498Z","shell.execute_reply.started":"2021-11-29T16:12:13.745981Z","shell.execute_reply":"2021-11-29T16:14:42.468401Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate the model with 2C1D","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:14:42.470706Z","iopub.execute_input":"2021-11-29T16:14:42.471634Z","iopub.status.idle":"2021-11-29T16:14:47.717416Z","shell.execute_reply.started":"2021-11-29T16:14:42.471591Z","shell.execute_reply":"2021-11-29T16:14:47.716515Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### 3C1D\n\nCreate a model with 3 convolutions and one dense layer.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:14:47.719439Z","iopub.execute_input":"2021-11-29T16:14:47.719805Z","iopub.status.idle":"2021-11-29T16:17:05.776802Z","shell.execute_reply.started":"2021-11-29T16:14:47.719747Z","shell.execute_reply":"2021-11-29T16:17:05.775740Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"##### Evaluate the model with 3 Convolutions and 1 Dense layer","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:17:05.778424Z","iopub.execute_input":"2021-11-29T16:17:05.778856Z","iopub.status.idle":"2021-11-29T16:17:11.329401Z","shell.execute_reply.started":"2021-11-29T16:17:05.778797Z","shell.execute_reply":"2021-11-29T16:17:11.328155Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Let us now try deeper structures. Maybe a model with 2 X 2 X 1 convolution and 1 Dense layer\n\n### 2x2x1C1D","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', \n               optimizer=optimizers.RMSprop(lr=1e-4),\n               metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:17:11.333248Z","iopub.execute_input":"2021-11-29T16:17:11.333562Z","iopub.status.idle":"2021-11-29T16:20:28.501397Z","shell.execute_reply.started":"2021-11-29T16:17:11.333505Z","shell.execute_reply":"2021-11-29T16:20:28.500398Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the model performance.","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:20:28.503302Z","iopub.execute_input":"2021-11-29T16:20:28.503849Z","iopub.status.idle":"2021-11-29T16:20:38.879255Z","shell.execute_reply.started":"2021-11-29T16:20:28.503781Z","shell.execute_reply":"2021-11-29T16:20:38.878175Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"Try Adam optimizer insted of RMSprop for faster convergence.\n\n### 2x2x1C1D Adam\n","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:20:38.881251Z","iopub.execute_input":"2021-11-29T16:20:38.881536Z","iopub.status.idle":"2021-11-29T16:23:49.778174Z","shell.execute_reply.started":"2021-11-29T16:20:38.881495Z","shell.execute_reply":"2021-11-29T16:23:49.775372Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"Evaluate the prformnace of the model with Adam optimiser","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:23:49.779765Z","iopub.execute_input":"2021-11-29T16:23:49.780216Z","iopub.status.idle":"2021-11-29T16:23:55.301352Z","shell.execute_reply.started":"2021-11-29T16:23:49.780132Z","shell.execute_reply":"2021-11-29T16:23:55.300360Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Try Batch Normalization for improving the performance \n### 2x2x1C1D BatchNorm","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(96, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(96, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', \n               optimizer=optimizers.RMSprop(lr=1e-4),\n               metrics=['accuracy', 'Recall'])\n\n\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:23:55.303398Z","iopub.execute_input":"2021-11-29T16:23:55.304137Z","iopub.status.idle":"2021-11-29T16:29:32.674850Z","shell.execute_reply.started":"2021-11-29T16:23:55.304088Z","shell.execute_reply":"2021-11-29T16:29:32.673930Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:29:32.678335Z","iopub.execute_input":"2021-11-29T16:29:32.678579Z","iopub.status.idle":"2021-11-29T16:29:38.738860Z","shell.execute_reply.started":"2021-11-29T16:29:32.678547Z","shell.execute_reply":"2021-11-29T16:29:38.737912Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Try Adam optimizer insted of RMSprop for faster convergence and also  add Batch Normalization improved performance\n\n### 2x2x1C1D Adam/ BatchNorm\n\n","metadata":{}},{"cell_type":"code","source":"\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(96, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(96, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:29:38.740375Z","iopub.execute_input":"2021-11-29T16:29:38.740725Z","iopub.status.idle":"2021-11-29T16:34:51.561247Z","shell.execute_reply.started":"2021-11-29T16:29:38.740660Z","shell.execute_reply":"2021-11-29T16:34:51.560224Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:34:51.562923Z","iopub.execute_input":"2021-11-29T16:34:51.563909Z","iopub.status.idle":"2021-11-29T16:34:56.977137Z","shell.execute_reply.started":"2021-11-29T16:34:51.563861Z","shell.execute_reply":"2021-11-29T16:34:56.976091Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"### 2x2x1C1D Dropout\n\nTry adding Droupout to combat overfitiing","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', \n               optimizer=optimizers.RMSprop(lr=1e-4),\n               metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=5, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:34:56.979469Z","iopub.execute_input":"2021-11-29T16:34:56.979852Z","iopub.status.idle":"2021-11-29T16:38:17.383289Z","shell.execute_reply.started":"2021-11-29T16:34:56.979781Z","shell.execute_reply":"2021-11-29T16:38:17.382364Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:38:17.384960Z","iopub.execute_input":"2021-11-29T16:38:17.385394Z","iopub.status.idle":"2021-11-29T16:38:22.213279Z","shell.execute_reply.started":"2021-11-29T16:38:17.385353Z","shell.execute_reply":"2021-11-29T16:38:22.212150Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"### 2X2C1D ","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation = 'relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=8, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:38:22.215212Z","iopub.execute_input":"2021-11-29T16:38:22.216874Z","iopub.status.idle":"2021-11-29T16:43:35.710076Z","shell.execute_reply.started":"2021-11-29T16:38:22.216823Z","shell.execute_reply":"2021-11-29T16:43:35.708793Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:43:35.712202Z","iopub.execute_input":"2021-11-29T16:43:35.712561Z","iopub.status.idle":"2021-11-29T16:43:40.854529Z","shell.execute_reply.started":"2021-11-29T16:43:35.712516Z","shell.execute_reply":"2021-11-29T16:43:40.853382Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"### 2x2C1D Dropout\n\nTry adding Dropout to combat overfitting.","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation = 'relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(),\n              metrics=['accuracy', 'Recall'])\n\nstart = timer()\n\nhistory = model.fit(train_generator, \n                    epochs=8, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )\n\nend = timer()\nelapsed = end - start\nprint('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:43:40.856499Z","iopub.execute_input":"2021-11-29T16:43:40.857689Z","iopub.status.idle":"2021-11-29T16:49:04.210599Z","shell.execute_reply.started":"2021-11-29T16:43:40.857645Z","shell.execute_reply":"2021-11-29T16:49:04.209478Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:49:04.216398Z","iopub.execute_input":"2021-11-29T16:49:04.216642Z","iopub.status.idle":"2021-11-29T16:49:09.064719Z","shell.execute_reply.started":"2021-11-29T16:49:04.216612Z","shell.execute_reply":"2021-11-29T16:49:09.063800Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\n#model.name=\"KAllCnn_IDB1\"\n\nmodel.add(tf.keras.layers.ZeroPadding2D(padding=(2, 2), input_shape= (256,256,3)))\nmodel.add(layers.Conv2D(30, (5, 5), strides=1, padding = \"valid\", input_shape = (256,256,3), activation = 'relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(tf.keras.layers.ZeroPadding2D(padding=(2, 2), input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(30, (5, 5), strides=1, padding = \"valid\", activation = 'relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding = 'valid'))\nmodel.add(layers.Dropout(0.6))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1))\nmodel.add(layers.Activation(\"softmax\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-6),\n              metrics=['accuracy', 'Recall'])\n\n\n\nhistory = model.fit(train_generator, \n                    epochs=8, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test_generator, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualkeras.layered_view(model,legend=True,  to_file='Final.png')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]}]}