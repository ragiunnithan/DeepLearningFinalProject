{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport imageio\nimport numpy as np \nfrom timeit import default_timer as timer\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import models, layers, optimizers\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-02T16:13:25.934732Z","iopub.execute_input":"2021-12-02T16:13:25.935175Z","iopub.status.idle":"2021-12-02T16:13:31.893007Z","shell.execute_reply.started":"2021-12-02T16:13:25.935071Z","shell.execute_reply":"2021-12-02T16:13:31.892056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold0_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0/all\"\nfold1_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1/all\"\nfold2_all = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2/all\"\n\n#hem is the normal one\nfold0_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0/hem\"\nfold1_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1/hem\"\nfold2_nrml = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2/hem\"\n\ntest_data = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data/\"\ntest_labels = pd.read_csv(\"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:31.895421Z","iopub.execute_input":"2021-12-02T16:13:31.895733Z","iopub.status.idle":"2021-12-02T16:13:31.930383Z","shell.execute_reply.started":"2021-12-02T16:13:31.895690Z","shell.execute_reply":"2021-12-02T16:13:31.929576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path_image(folder):\n    image_paths = []\n    image_fnames = os.listdir(folder) \n    for img_id in range(len(image_fnames)):\n        img = os.path.join(folder,image_fnames[img_id])\n        image_paths.append(img)\n    \n    return image_paths","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:31.931706Z","iopub.execute_input":"2021-12-02T16:13:31.932345Z","iopub.status.idle":"2021-12-02T16:13:31.939330Z","shell.execute_reply.started":"2021-12-02T16:13:31.932304Z","shell.execute_reply":"2021-12-02T16:13:31.938194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image absolute paths for cancer cells and normal cells\ncancer_lst = []\n\nfor i in [fold0_all,fold1_all,fold2_all]:\n    paths = get_path_image(i)\n    cancer_lst.extend(paths)\n    \n    \nprint(len(cancer_lst))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:31.940722Z","iopub.execute_input":"2021-12-02T16:13:31.942000Z","iopub.status.idle":"2021-12-02T16:13:32.911136Z","shell.execute_reply.started":"2021-12-02T16:13:31.941939Z","shell.execute_reply":"2021-12-02T16:13:32.910189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_lst = []\nfor i in [fold0_nrml,fold1_nrml,fold2_nrml]:\n    paths = get_path_image(i)\n    normal_lst.extend(paths)\n   \n   \nprint(len(normal_lst))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:32.914606Z","iopub.execute_input":"2021-12-02T16:13:32.915453Z","iopub.status.idle":"2021-12-02T16:13:33.541511Z","shell.execute_reply.started":"2021-12-02T16:13:32.915420Z","shell.execute_reply":"2021-12-02T16:13:33.540450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cancer_dict = {\"x_col\":cancer_lst,\n          \"y_col\":[np.nan for x in range(len(cancer_lst))]}\n\n\ncancer_dict[\"y_col\"] = \"ALL\"\n\nnormal_dict = {\"x_col\":normal_lst,\n          \"y_col\":[np.nan for x in range(len(normal_lst))]}\n\n\nnormal_dict[\"y_col\"] = \"HEM\"\n\ncancer_df = pd.DataFrame(cancer_dict)\nnormal_df = pd.DataFrame(normal_dict)\n\ntrain_df = cancer_df.append(normal_df, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:33.542959Z","iopub.execute_input":"2021-12-02T16:13:33.543995Z","iopub.status.idle":"2021-12-02T16:13:33.558123Z","shell.execute_reply.started":"2021-12-02T16:13:33.543952Z","shell.execute_reply":"2021-12-02T16:13:33.556841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_len = len(cancer_df)\nnorm_len = len(normal_df)\n\nnrm_size = int((norm_len/100) * 25)\nall_size = int((all_len/100) * 25)\nvalidation_df = pd.DataFrame()\nvalidation_df = validation_df.append(normal_df[0:nrm_size])\nvalidation_df = validation_df.append(cancer_df[0:all_size]) \n\ntrain_df = pd.DataFrame()\ntrain_df = train_df.append(normal_df[nrm_size : norm_len])\ntrain_df = train_df.append(cancer_df[all_size : all_len])   ","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:33.561481Z","iopub.execute_input":"2021-12-02T16:13:33.562646Z","iopub.status.idle":"2021-12-02T16:13:33.576104Z","shell.execute_reply.started":"2021-12-02T16:13:33.562581Z","shell.execute_reply":"2021-12-02T16:13:33.575096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the validation data\ntest_list = get_path_image(test_data)\n\n\n##Convert the list to a dictionary. The labels are stored in the val_labels\n#3So we create a dictionary with x as the file name and y as the labels\n##The labels are having 0's and 1's.\n##0 means normal and 1 means cancer - ALL\n\ntest_dict = {\"x_col\":test_list,\n                   \"y_col\":test_labels[\"labels\"]}\n\ntest_df = pd.DataFrame(test_dict)\n\ntest_df[\"y_col\"].replace(to_replace = [1,0], value = [\"ALL\",\"HEM\"], inplace = True)\n#test_df = test_df[1:200]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:33.579801Z","iopub.execute_input":"2021-12-02T16:13:33.580916Z","iopub.status.idle":"2021-12-02T16:13:33.875147Z","shell.execute_reply.started":"2021-12-02T16:13:33.580869Z","shell.execute_reply":"2021-12-02T16:13:33.874229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255 #pixel values are 255 maximum\n         )\n\n\ntest_datagen = ImageDataGenerator(\n        rescale=1./255 )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                  train_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),\n                 \n                  #batch_size = 32,\n                  color_mode = \"rgb\",\n                  shuffle = True,\n                  class_mode = \"binary\"\n                  )\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n                  validation_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),                  \n                  #batch_size = 32,\n                  color_mode = \"rgb\",\n                  shuffle = True,\n                  class_mode = \"binary\"\n                  )\ntest_generator = test_datagen.flow_from_dataframe(\n                  test_df,\n                  x_col = \"x_col\",\n                  y_col = \"y_col\",\n                  target_size = (256, 256),\n                  color_mode = \"rgb\",\n                  class_mode = \"binary\",\n                  shuffle = False)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:33.876735Z","iopub.execute_input":"2021-12-02T16:13:33.877340Z","iopub.status.idle":"2021-12-02T16:13:48.524716Z","shell.execute_reply.started":"2021-12-02T16:13:33.877300Z","shell.execute_reply":"2021-12-02T16:13:48.523704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Final Model Summary - 2x2C1D Dropout","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, 3, activation = 'relu', input_shape=(256,256,3)))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.Conv2D(64, 3, activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation = 'relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(),\n              metrics=['accuracy','Recall'])\n\nhistory = model.fit(train_generator, \n                    epochs=100, \n                    validation_data=validation_generator, \n                    workers = 7\n                   )","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:13:48.526602Z","iopub.execute_input":"2021-12-02T16:13:48.527281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test_generator, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/paulgavrikov/visualkeras\nimport visualkeras\nvisualkeras.layered_view(model,legend=True,  to_file='Final.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_metric(history, metric):\n    '''\n    history: return value of the .fit, which includes all the history while training the model\n    metric: which metric to plot\n    '''\n    train_metrics = history.history[metric]\n    validation_metrics = history.history['val_' + metric]\n    \n    # make it start from 1\n    train_epochs = range(1, len(train_metrics) + 1)\n    \n    sns.set(color_codes=True)\n    plt.figure(1, figsize=(8, 6))\n    plt.plot(train_epochs, train_metrics)\n    plt.plot(train_epochs, validation_metrics)\n    \n    plt.title('Training and Validation '+ metric)\n    \n    plt.xlabel(\"Number of Epochs\")\n    plt.ylabel(metric)\n    \n    plt.legend([\"Training \" + metric, \"Validation \" + metric])\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nshow_metric(history, \"accuracy\")\nshow_metric(history, \"loss\")\nshow_metric(history, \"Recall\")    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_generator = train_gen.flow_from_dataframe(\n    train_df,\n    x_col=\"x_col\",\n    y_col=\"y_col\",\n    target_size=(227, 227),\n    batch_size=32,\n    color_mode=\"rgb\",\n    shuffle=True,\n    class_mode='binary')\n\nval_generator = train_gen.flow_from_dataframe(\n    validation_df,\n    x_col=\"x_col\",\n    y_col=\"y_col\",\n    target_size=(227, 227),\n    batch_size=32,\n    color_mode=\"rgb\",\n    shuffle=True,\n    class_mode='binary')\ndef alexnet(train_generator,epchs,val_generator,batch_size,lr):\n    \n    model = models.Sequential()\n    opt = tf.keras.optimizers.Nadam(learning_rate=lr,decay=1e-4)\n    callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                                          patience=10,\n                                          verbose=2)\n    #building architecture\n    #Adding layers\n    model.add(layers.Conv2D(96,(11,11),\n                               strides=4,\n                               activation=\"elu\",\n                               name=\"layer1\",\n                               input_shape=(227,227,3))) \n    model.add(layers.MaxPooling2D((3,3),strides=2,name=\"layer2\"))\n    model.add(layers.Conv2D(256,(5,5),padding=\"valid\",activation=\"elu\",name=\"layer3\"))\n    model.add(layers.MaxPooling2D((3,3),strides=2,name=\"layer4\"))\n    model.add(layers.Conv2D(384,(3,3),padding=\"valid\",activation=\"elu\",name=\"layer5\"))\n    model.add(layers.Conv2D(384,(3,3),padding=\"valid\",activation=\"elu\",name=\"layer6\"))\n    model.add(layers.Conv2D(256,(3,3),padding=\"valid\",activation=\"elu\",name=\"layer7\"))\n    model.add(layers.MaxPooling2D((3,3),strides=2,name=\"layer8\"))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1024,activation=\"elu\",\n                              kernel_initializer=\"he_normal\",\n                              kernel_regularizer=ks.regularizers.l2(0.01)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(1024,activation=\"elu\",\n                               kernel_regularizer=ks.regularizers.l2(0.01)))\n    model.add(layers.BatchNormalization())\n    \n    model.add(layers.Dense(1,activation=\"sigmoid\",\n                              kernel_initializer=\"glorot_uniform\",\n                              name=\"output\"))#2 classes \n    summmry = model.summary()\n    #Compile the model.\n    #setting optimisation, cost funciton and metric to be used\n    model.compile(loss=\"binary_crossentropy\",\n                  optimizer=opt,\n                  metrics=[\"accuracy\"])\n    history = model.fit(train_generator,\n                        steps_per_epoch=100,\n                        epochs=epchs,\n                        callbacks=[callback],\n                        batch_size=batch_size,\n                        validation_data=val_generator,\n                        validation_steps=50)\n\nhistory2 = alexnet(train_generator,20,val_generator,batch_size=16,lr=1E+1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test_generator, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}